"""
å°é“ Agent æ ¸å¿ƒ

å‚è€ƒ OpenCode è®¾è®¡ä¼˜åŒ–ï¼š
1. äº‹ä»¶é©±åŠ¨æ¶æ„ - å®æ—¶ UI æ›´æ–°
2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥å–æ¶ˆ - ä¼˜é›…ä¸­æ–­
3. ä¼šè¯çŠ¶æ€ç®¡ç† - é˜²æ­¢å¹¶å‘å†²çª
4. æ™ºèƒ½å†å²ç®¡ç† - è‡ªåŠ¨æ‘˜è¦
5. å·¥å…·æ‰§è¡Œä¼˜åŒ– - é¡ºåº/å¹¶è¡Œæ¨¡å¼
"""

from __future__ import annotations

import asyncio
import time
import uuid
from dataclasses import dataclass
from typing import Callable, Dict, Optional

try:
    import tiktoken

    HAS_TIKTOKEN = True
except ImportError:
    HAS_TIKTOKEN = False

from .events import (
    AgentStartEvent,
    AgentStepEvent,
    Event,
    EventType,
    MessageDeltaEvent,
    ThinkingDeltaEvent,
    TokenUpdateEvent,
    ToolCompleteEvent,
    ToolStartEvent,
    get_event_broker,
)
from .llm import LLMClient
from .schema import LLMResponse, Message
from .tools import Tool


@dataclass
class AgentConfig:
    """Agent é…ç½®"""

    max_steps: int = 50
    token_limit: int = 100000
    parallel_tools: bool = True
    enable_thinking: bool = True
    stream: bool = True
    quiet: bool = False
    # æ‘˜è¦é…ç½®
    summary_threshold: float = 0.8  # è¾¾åˆ° token_limit çš„ 80% æ—¶è§¦å‘æ‘˜è¦
    summary_keep_recent: int = 5  # æ‘˜è¦æ—¶ä¿ç•™æœ€è¿‘ N æ¡ç”¨æˆ·æ¶ˆæ¯


class SessionState:
    """ä¼šè¯çŠ¶æ€ç®¡ç† - é˜²æ­¢å¹¶å‘å†²çª"""

    def __init__(self):
        self._busy_sessions: Dict[str, asyncio.Event] = {}
        self._lock = asyncio.Lock()

    async def acquire(self, session_id: str) -> bool:
        """è·å–ä¼šè¯é”"""
        async with self._lock:
            if session_id in self._busy_sessions:
                return False
            self._busy_sessions[session_id] = asyncio.Event()
            return True

    async def release(self, session_id: str):
        """é‡Šæ”¾ä¼šè¯é”"""
        async with self._lock:
            if session_id in self._busy_sessions:
                self._busy_sessions[session_id].set()
                del self._busy_sessions[session_id]

    def is_busy(self, session_id: str) -> bool:
        """æ£€æŸ¥ä¼šè¯æ˜¯å¦å¿™ç¢Œ"""
        return session_id in self._busy_sessions

    async def wait_for_release(self, session_id: str, timeout: float = 30.0) -> bool:
        """ç­‰å¾…ä¼šè¯é‡Šæ”¾"""
        if session_id not in self._busy_sessions:
            return True
        try:
            await asyncio.wait_for(self._busy_sessions[session_id].wait(), timeout=timeout)
            return True
        except asyncio.TimeoutError:
            return False


# å…¨å±€ä¼šè¯çŠ¶æ€
_session_state = SessionState()


class Agent:
    """å°é“ Agent - ä¼˜åŒ–ç‰ˆ"""

    def __init__(
        self,
        llm_client: LLMClient,
        system_prompt: str,
        tools: list[Tool],
        max_steps: int = 50,
        token_limit: int = 100000,
        workspace_dir: str = ".",
        stream: bool = True,
        enable_thinking: bool = True,
        quiet: bool = False,
        parallel_tools: bool = True,
        session_id: Optional[str] = None,
    ):
        self.llm = llm_client
        self.tools: dict[str, Tool] = {t.name: t for t in tools}
        self.workspace_dir = workspace_dir
        self.session_id = session_id or str(uuid.uuid4())[:8]

        # é…ç½®
        self.config = AgentConfig(
            max_steps=max_steps,
            token_limit=token_limit,
            parallel_tools=parallel_tools,
            enable_thinking=enable_thinking,
            stream=stream,
            quiet=quiet,
        )

        # å…¼å®¹æ—§å±æ€§
        self.max_steps = max_steps
        self.token_limit = token_limit
        self.stream = stream
        self.enable_thinking = enable_thinking
        self.quiet = quiet
        self.parallel_tools = parallel_tools

        # æ¶ˆæ¯å†å²
        self.messages: list[Message] = [Message(role="system", content=system_prompt)]

        # å–æ¶ˆæ§åˆ¶
        self.cancel_event: Optional[asyncio.Event] = None
        self._cancelled = False

        # Token ç»Ÿè®¡
        self.api_total_tokens = 0
        self.api_input_tokens = 0
        self.api_output_tokens = 0

        # tiktoken ç¼–ç å™¨
        self._encoding = None
        if HAS_TIKTOKEN:
            try:
                self._encoding = tiktoken.get_encoding("cl100k_base")
            except Exception:
                pass

        # äº‹ä»¶ä»£ç†
        self._event_broker = get_event_broker()

        # è¾“å‡ºå›è°ƒï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        self.on_thinking: Optional[Callable[[str], None]] = None
        self.on_content: Optional[Callable[[str], None]] = None

    def _check_cancelled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ"""
        if self._cancelled:
            return True
        if self.cancel_event is not None and self.cancel_event.is_set():
            self._cancelled = True
            return True
        return False

    def _cleanup_incomplete_messages(self):
        """æ¸…ç†æœªå®Œæˆçš„æ¶ˆæ¯ï¼ˆå–æ¶ˆæ—¶è°ƒç”¨ï¼‰"""
        # æ‰¾åˆ°æœ€åä¸€ä¸ª assistant æ¶ˆæ¯
        last_assistant_idx = -1
        for i in range(len(self.messages) - 1, -1, -1):
            if self.messages[i].role == "assistant":
                last_assistant_idx = i
                break

        # å¦‚æœæœ‰æœªå®Œæˆçš„ tool è°ƒç”¨ï¼Œåˆ é™¤ assistant åŠå…¶åçš„æ¶ˆæ¯
        if last_assistant_idx >= 0:
            assistant_msg = self.messages[last_assistant_idx]
            if assistant_msg.tool_calls:
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ tool è°ƒç”¨éƒ½æœ‰ç»“æœ
                tool_call_ids = {tc.id for tc in assistant_msg.tool_calls}
                result_ids = set()
                for msg in self.messages[last_assistant_idx + 1 :]:
                    if msg.role == "tool" and msg.tool_call_id:
                        result_ids.add(msg.tool_call_id)

                if tool_call_ids != result_ids:
                    # æœ‰æœªå®Œæˆçš„è°ƒç”¨ï¼Œåˆ é™¤
                    self.messages = self.messages[:last_assistant_idx]

    def _estimate_tokens(self) -> int:
        """ä¼°ç®—å½“å‰æ¶ˆæ¯çš„ token æ•°"""
        if self._encoding is None:
            # æ²¡æœ‰ tiktokenï¼ŒæŒ‰å­—ç¬¦ä¼°ç®—
            total_chars = sum(
                len(str(msg.content)) + len(str(msg.thinking or "")) for msg in self.messages
            )
            return total_chars // 4

        total = 0
        for msg in self.messages:
            if isinstance(msg.content, str):
                total += len(self._encoding.encode(msg.content))
            if msg.thinking:
                total += len(self._encoding.encode(msg.thinking))
        return total

    async def _should_summarize(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ‘˜è¦"""
        estimated = self._estimate_tokens()
        threshold = int(self.config.token_limit * self.config.summary_threshold)
        return estimated > threshold or self.api_total_tokens > threshold

    async def _summarize_messages(self):
        """æ™ºèƒ½æ‘˜è¦å†å²æ¶ˆæ¯"""
        if not await self._should_summarize():
            return

        estimated = self._estimate_tokens()
        if not self.quiet:
            print(f"âš ï¸ Token æ¥è¿‘é™åˆ¶ ({estimated}/{self.config.token_limit})ï¼Œæ­£åœ¨æ‘˜è¦...")

        # ä¿ç•™ system æ¶ˆæ¯
        system_msg = self.messages[0] if self.messages[0].role == "system" else None
        new_messages = [system_msg] if system_msg else []

        # åˆ†ç¦»ç”¨æˆ·æ¶ˆæ¯å’Œå…¶ä»–æ¶ˆæ¯
        user_messages = []
        other_messages = []

        for msg in self.messages[1:]:
            if msg.role == "user":
                user_messages.append(msg)
            else:
                other_messages.append(msg)

        # ä¿ç•™æœ€è¿‘çš„ç”¨æˆ·æ¶ˆæ¯
        keep_recent = self.config.summary_keep_recent
        recent_user_msgs = (
            user_messages[-keep_recent:] if len(user_messages) > keep_recent else user_messages
        )
        old_user_msgs = user_messages[:-keep_recent] if len(user_messages) > keep_recent else []

        # æ”¶é›†éœ€è¦æ‘˜è¦çš„å†…å®¹
        content_to_summarize = []
        for msg in old_user_msgs:
            content_to_summarize.append(f"[ç”¨æˆ·]: {msg.content[:200]}")
        for msg in other_messages[:-10]:  # ä¿ç•™æœ€è¿‘ 10 æ¡å…¶ä»–æ¶ˆæ¯
            if msg.content:
                content_to_summarize.append(f"[{msg.role}]: {str(msg.content)[:200]}")

        if content_to_summarize:
            # ç”Ÿæˆæ‘˜è¦
            summary_prompt = "è¯·ç”¨ä¸­æ–‡ç®€æ´æ‘˜è¦ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼ˆä¿ç•™å…³é”®ä¿¡æ¯å’Œå†³ç­–ï¼‰:\n\n" + "\n".join(
                content_to_summarize[-30:]
            )
            try:
                summary_response = await self.llm.generate(
                    [Message(role="user", content=summary_prompt)]
                )
                summary = summary_response.content

                # æ·»åŠ æ‘˜è¦æ¶ˆæ¯
                new_messages.append(Message(role="assistant", content=f"[å†å²æ‘˜è¦]\n{summary}"))
            except Exception as e:
                if not self.quiet:
                    print(f"âš ï¸ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")

        # æ·»åŠ ä¿ç•™çš„ç”¨æˆ·æ¶ˆæ¯
        new_messages.extend(recent_user_msgs)

        # æ·»åŠ æœ€è¿‘çš„å…¶ä»–æ¶ˆæ¯
        new_messages.extend(other_messages[-10:])

        self.messages = new_messages
        if not self.quiet:
            print(f"âœ… æ‘˜è¦å®Œæˆï¼Œæ¶ˆæ¯æ•°: {len(self.messages)}")

    async def _publish_event(self, event: Event):
        """å‘å¸ƒäº‹ä»¶"""
        event.session_id = self.session_id
        await self._event_broker.publish(event)

    async def run(self, user_input: Optional[str] = None) -> str:
        """è¿è¡Œ Agent - ä¸»å¾ªç¯"""
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å¿™ç¢Œ
        if _session_state.is_busy(self.session_id):
            return "âš ï¸ ä¼šè¯æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™"

        # è·å–ä¼šè¯é”
        if not await _session_state.acquire(self.session_id):
            return "âš ï¸ æ— æ³•è·å–ä¼šè¯é”"

        self._cancelled = False

        try:
            # æ·»åŠ ç”¨æˆ·è¾“å…¥
            if user_input:
                self.messages.append(Message(role="user", content=user_input))
                await self._publish_event(
                    AgentStartEvent(
                        user_input=user_input, data={"message_count": len(self.messages)}
                    )
                )

            return await self._run_loop()

        finally:
            # é‡Šæ”¾ä¼šè¯é”
            await _session_state.release(self.session_id)

    async def _run_loop(self) -> str:
        """Agent æ‰§è¡Œå¾ªç¯"""
        for step in range(self.config.max_steps):
            # æ£€æŸ¥å–æ¶ˆ
            if self._check_cancelled():
                self._cleanup_incomplete_messages()
                await self._publish_event(Event(type=EventType.AGENT_CANCEL))
                return "âš ï¸ ä»»åŠ¡å·²å–æ¶ˆ"

            # å‘å¸ƒæ­¥éª¤äº‹ä»¶
            await self._publish_event(
                AgentStepEvent(
                    step=step + 1,
                    total_steps=self.config.max_steps,
                )
            )

            # Token ç®¡ç†
            await self._summarize_messages()

            # è·å–å·¥å…· schema
            tool_schemas = [tool.to_schema() for tool in self.tools.values()]

            # è°ƒç”¨ LLM
            try:
                if self.config.stream:
                    response = await self._stream_generate(tool_schemas)
                else:
                    response = await self.llm.generate(
                        messages=self.messages,
                        tools=tool_schemas if tool_schemas else None,
                    )
            except Exception as e:
                await self._publish_event(Event(type=EventType.AGENT_ERROR, data={"error": str(e)}))
                return f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}"

            # æ›´æ–° token ç»Ÿè®¡
            if response.usage:
                self.api_total_tokens = response.usage.total_tokens
                self.api_input_tokens = response.usage.input_tokens
                self.api_output_tokens = response.usage.output_tokens
                await self._publish_event(
                    TokenUpdateEvent(
                        input_tokens=response.usage.input_tokens,
                        output_tokens=response.usage.output_tokens,
                        total_tokens=response.usage.total_tokens,
                    )
                )

            # æ·»åŠ  assistant æ¶ˆæ¯
            self.messages.append(
                Message(
                    role="assistant",
                    content=response.content,
                    thinking=response.thinking,
                    tool_calls=response.tool_calls,
                )
            )

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å®Œæˆ
            if not response.tool_calls:
                await self._publish_event(
                    Event(type=EventType.AGENT_COMPLETE, data={"content": response.content})
                )
                return response.content

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            if self.config.parallel_tools and len(response.tool_calls) > 1:
                tool_results = await self._execute_tools_parallel(response.tool_calls)
            else:
                tool_results = await self._execute_tools_sequential(response.tool_calls)

            # æ£€æŸ¥å–æ¶ˆï¼ˆå·¥å…·æ‰§è¡Œåï¼‰
            if self._check_cancelled():
                self._cleanup_incomplete_messages()
                return "âš ï¸ ä»»åŠ¡å·²å–æ¶ˆ"

            # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
            for tool_call_id, function_name, result_content in tool_results:
                self.messages.append(
                    Message(
                        role="tool",
                        content=result_content,
                        tool_call_id=tool_call_id,
                        name=function_name,
                    )
                )

        return "âš ï¸ è¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶"

    async def _execute_tools_sequential(self, tool_calls: list) -> list[tuple[str, str, str]]:
        """é¡ºåºæ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆå‚è€ƒ OpenCode è®¾è®¡ï¼‰"""
        results = []

        for tool_call in tool_calls:
            # æ£€æŸ¥å–æ¶ˆ
            if self._check_cancelled():
                # æ ‡è®°å‰©ä½™å·¥å…·ä¸ºå·²å–æ¶ˆ
                results.append((tool_call.id, tool_call.function.name, "âš ï¸ å·²å–æ¶ˆ"))
                continue

            result = await self._execute_single_tool(tool_call)
            results.append(result)

        return results

    async def _execute_tools_parallel(self, tool_calls: list) -> list[tuple[str, str, str]]:
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·è°ƒç”¨"""
        if self._check_cancelled():
            return []

        if not self.quiet:
            print(f"\nâš¡ å¹¶è¡Œæ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·...")

        start_time = time.time()
        tasks = [self._execute_single_tool(tc) for tc in tool_calls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        elapsed = time.time() - start_time

        if not self.quiet:
            print(f"   â±ï¸ å®Œæˆï¼Œæ€»è€—æ—¶ {elapsed:.2f}s")

        # å¤„ç†ç»“æœ
        final_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                tc = tool_calls[i]
                final_results.append((tc.id, tc.function.name, f"æ‰§è¡Œå¼‚å¸¸: {result}"))
            else:
                final_results.append(result)

        return final_results

    async def _execute_single_tool(self, tool_call) -> tuple[str, str, str]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        tool_call_id = tool_call.id
        function_name = tool_call.function.name
        arguments = tool_call.function.arguments

        # å‘å¸ƒå·¥å…·å¼€å§‹äº‹ä»¶
        await self._publish_event(
            ToolStartEvent(
                tool_name=function_name,
                tool_id=tool_call_id,
                arguments=arguments,
            )
        )

        # æ ¼å¼åŒ–å‚æ•°æ˜¾ç¤º
        if not self.quiet:
            args_display = ", ".join(f"{k}={repr(v)[:50]}" for k, v in arguments.items())
            print(f"\nğŸ”§ {function_name}({args_display})")

        tool = self.tools.get(function_name)
        if not tool:
            result_content = f"é”™è¯¯: æœªçŸ¥å·¥å…· '{function_name}'"
            if not self.quiet:
                print(f"   âŒ {result_content}")
            await self._publish_event(
                ToolCompleteEvent(
                    tool_name=function_name,
                    tool_id=tool_call_id,
                    success=False,
                    error=result_content,
                )
            )
            return (tool_call_id, function_name, result_content)

        try:
            start_time = time.time()
            result = await tool.execute(**arguments)
            elapsed = time.time() - start_time

            if result.success:
                result_content = result.content
                # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                if not self.quiet:
                    preview = result_content[:100].replace("\n", " ")
                    if len(result_content) > 100:
                        preview += "..."
                    print(f"   âœ… ({elapsed:.1f}s) {preview}")

                await self._publish_event(
                    ToolCompleteEvent(
                        tool_name=function_name,
                        tool_id=tool_call_id,
                        success=True,
                        result=result_content[:500],
                        duration=elapsed,
                    )
                )
            else:
                result_content = f"é”™è¯¯: {result.error}"
                if not self.quiet:
                    print(f"   âŒ ({elapsed:.1f}s) {result.error}")

                await self._publish_event(
                    ToolCompleteEvent(
                        tool_name=function_name,
                        tool_id=tool_call_id,
                        success=False,
                        error=result.error,
                        duration=elapsed,
                    )
                )

        except Exception as e:
            result_content = f"æ‰§è¡Œå¼‚å¸¸: {e}"
            if not self.quiet:
                print(f"   âŒ {result_content}")

            await self._publish_event(
                ToolCompleteEvent(
                    tool_name=function_name,
                    tool_id=tool_call_id,
                    success=False,
                    error=str(e),
                )
            )

        return (tool_call_id, function_name, result_content)

    async def _stream_generate(self, tool_schemas: list) -> LLMResponse:
        """æµå¼ç”Ÿæˆå“åº”"""
        thinking_started = False
        content_started = False

        async def on_thinking(text: str):
            nonlocal thinking_started
            if self.quiet:
                return
            if not thinking_started:
                if not self.on_thinking:
                    # åªæœ‰åœ¨æ²¡æœ‰å¤–éƒ¨å›è°ƒæ—¶æ‰æ‰“å°æ ‡é¢˜
                    print("\nğŸ’­ æ€è€ƒä¸­...", flush=True)
                thinking_started = True
                await self._publish_event(Event(type=EventType.THINKING_START))

            # å‘å¸ƒæ€è€ƒå¢é‡äº‹ä»¶
            await self._publish_event(ThinkingDeltaEvent(content=text))

            # è°ƒç”¨å›è°ƒ
            if self.on_thinking:
                self.on_thinking(text)

        async def on_content(text: str):
            nonlocal content_started
            if self.quiet:
                return
            if not content_started:
                if not self.on_content:
                    # åªæœ‰åœ¨æ²¡æœ‰å¤–éƒ¨å›è°ƒæ—¶æ‰æ‰“å°æ ‡é¢˜
                    print("\nğŸ¤– å°é“:", flush=True)
                content_started = True
                await self._publish_event(Event(type=EventType.MESSAGE_START))

            # åªæœ‰åœ¨æ²¡æœ‰å¤–éƒ¨å›è°ƒæ—¶æ‰ç›´æ¥æ‰“å°
            if not self.on_content:
                print(text, end="", flush=True)

            # å‘å¸ƒæ¶ˆæ¯å¢é‡äº‹ä»¶
            await self._publish_event(MessageDeltaEvent(content=text))

            # è°ƒç”¨å›è°ƒ
            if self.on_content:
                self.on_content(text)

        # åŒ…è£…åŒæ­¥å›è°ƒä¸ºå¼‚æ­¥
        def sync_on_thinking(text: str):
            asyncio.create_task(on_thinking(text))

        def sync_on_content(text: str):
            asyncio.create_task(on_content(text))

        response = await self.llm.generate_stream(
            messages=self.messages,
            tools=tool_schemas if tool_schemas else None,
            on_thinking=sync_on_thinking,
            on_content=sync_on_content,
            enable_thinking=self.config.enable_thinking,
        )

        if content_started and not self.quiet:
            print()  # æ¢è¡Œ

        if thinking_started:
            await self._publish_event(Event(type=EventType.THINKING_COMPLETE))
        if content_started:
            await self._publish_event(Event(type=EventType.MESSAGE_COMPLETE))

        return response

    def reset(self):
        """é‡ç½® Agent çŠ¶æ€"""
        system_msg = (
            self.messages[0] if self.messages and self.messages[0].role == "system" else None
        )
        self.messages = [system_msg] if system_msg else []
        self.api_total_tokens = 0
        self.api_input_tokens = 0
        self.api_output_tokens = 0
        self._cancelled = False

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "session_id": self.session_id,
            "message_count": len(self.messages),
            "estimated_tokens": self._estimate_tokens(),
            "api_total_tokens": self.api_total_tokens,
            "api_input_tokens": self.api_input_tokens,
            "api_output_tokens": self.api_output_tokens,
            "tool_count": len(self.tools),
            "parallel_tools": self.config.parallel_tools,
            "enable_thinking": self.config.enable_thinking,
        }
