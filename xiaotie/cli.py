"""
å°é“ CLI å…¥å£

äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢ v0.4.0
- æ–°å‘½ä»¤ç³»ç»Ÿï¼ˆçº¦å®šä¼˜äºé…ç½®ï¼‰
- å¢å¼ºæ˜¾ç¤ºï¼ˆMarkdown æ¸²æŸ“ã€ä»£ç é«˜äº®ï¼‰
- æ’ä»¶ç³»ç»Ÿæ”¯æŒ
- TUI æ¨¡å¼æ”¯æŒ
- éäº¤äº’æ¨¡å¼æ”¯æŒ
"""

from __future__ import annotations

import argparse
import asyncio
import json
import sys
from pathlib import Path

from .agent import Agent
from .config import Config
from .llm import LLMClient, LLMProvider
from .retry import RetryConfig
from .tools import (
    ReadTool, WriteTool, EditTool, BashTool,
    PythonTool, CalculatorTool, GitTool,
    WebSearchTool, WebFetchTool, CodeAnalysisTool,
)
from .banner import print_banner, print_status, print_ready, VERSION
from .session import SessionManager
from .commands import Commands
from .display import Display, StreamDisplay, get_display, set_display
from .plugins import PluginManager
from .input import EnhancedInput


def create_tools(config: Config, workspace: Path) -> list:
    """åˆ›å»ºå·¥å…·åˆ—è¡¨"""
    tools = []

    if config.tools.enable_file_tools:
        tools.extend([
            ReadTool(workspace_dir=str(workspace)),
            WriteTool(workspace_dir=str(workspace)),
            EditTool(workspace_dir=str(workspace)),
        ])

    if config.tools.enable_bash:
        tools.append(BashTool())

    # ä»£ç å·¥å…·
    tools.append(PythonTool())
    tools.append(CalculatorTool())

    # Git å·¥å…·
    tools.append(GitTool(workspace_dir=str(workspace)))

    # Web å·¥å…·
    tools.append(WebSearchTool())
    tools.append(WebFetchTool())

    # ä»£ç åˆ†æå·¥å…·
    tools.append(CodeAnalysisTool(workspace_dir=str(workspace)))

    return tools


def load_system_prompt(config: Config) -> str:
    """åŠ è½½ç³»ç»Ÿæç¤ºè¯"""
    prompt_path = Config.find_config_file(config.agent.system_prompt_path)

    if prompt_path and prompt_path.exists():
        return prompt_path.read_text(encoding="utf-8")

    # é»˜è®¤æç¤ºè¯
    return """ä½ æ˜¯å°é“ï¼Œä¸€ä¸ªæ™ºèƒ½ AI åŠ©æ‰‹ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»»åŠ¡ï¼š
- read_file: è¯»å–æ–‡ä»¶å†…å®¹
- write_file: å†™å…¥æ–‡ä»¶
- edit_file: ç¼–è¾‘æ–‡ä»¶ï¼ˆç²¾ç¡®æ›¿æ¢ï¼‰
- bash: æ‰§è¡Œ shell å‘½ä»¤
- python: æ‰§è¡Œ Python ä»£ç 
- calculator: æ•°å­¦è®¡ç®—
- git: Git ç‰ˆæœ¬æ§åˆ¶æ“ä½œ
- web_search: ç½‘ç»œæœç´¢
- web_fetch: è·å–ç½‘é¡µå†…å®¹

è¯·ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ï¼Œä¿æŒç®€æ´ä¸“ä¸šã€‚"""


async def interactive_loop(
    agent: Agent,
    session_mgr: SessionManager,
    plugin_mgr: PluginManager,
    display: Display,
):
    """äº¤äº’å¾ªç¯"""
    # åˆ›å»ºå‘½ä»¤ç®¡ç†å™¨
    commands = Commands(agent, session_mgr, plugin_mgr)

    # åˆ›å»ºå¢å¼ºè¾“å…¥ï¼ˆæ”¯æŒè‡ªåŠ¨è¡¥å…¨å’Œå†å²è®°å½•ï¼‰
    enhanced_input = EnhancedInput(commands=commands)

    display.info("è¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©ï¼Œ/quit é€€å‡º")
    if enhanced_input.use_prompt_toolkit:
        display.info("æ”¯æŒ Tab è¡¥å…¨ã€â†‘â†“ å†å²è®°å½•ã€Ctrl+R æœç´¢å†å²")
    print()

    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            try:
                user_input = enhanced_input.prompt("\nğŸ‘¤ ä½ : ").strip()
            except EOFError:
                break

            if not user_input:
                continue

            # å¤„ç†å‘½ä»¤
            if user_input.startswith("/"):
                cmd_line = user_input[1:]  # å»æ‰ /
                should_continue, message = await commands.execute(cmd_line)
                if message:
                    print(message)
                if not should_continue:
                    break
                continue

            # è¿è¡Œ Agent
            cancel_event = asyncio.Event()
            agent.cancel_event = cancel_event

            # åˆ›å»ºæµå¼æ˜¾ç¤ºå™¨
            stream_display = StreamDisplay(display)

            # è®¾ç½®å›è°ƒ
            agent.on_thinking = stream_display.on_thinking
            agent.on_content = stream_display.on_content

            try:
                await agent.run(user_input)
                stream_display.finish()
            except KeyboardInterrupt:
                cancel_event.set()
                print("\nâš ï¸ å·²å–æ¶ˆ")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except EOFError:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break


async def main_async(stream: bool = True, thinking: bool = True):
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–æ˜¾ç¤º
    display = Display()
    set_display(display)

    # åŠ è½½é…ç½®
    try:
        config = Config.load()
    except (FileNotFoundError, ValueError) as e:
        # å…ˆæ˜¾ç¤º bannerï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
        print_banner(workspace=str(Path.cwd()))
        print_status(str(e), "error")
        print("\nè¯·åˆ›å»ºé…ç½®æ–‡ä»¶ config/config.yamlï¼Œç¤ºä¾‹:")
        print("""
api_key: YOUR_API_KEY
api_base: https://api.anthropic.com
model: claude-sonnet-4-20250514
provider: anthropic
""")
        sys.exit(1)

    # åˆ›å»ºå·¥ä½œç›®å½•
    workspace = Path(config.agent.workspace_dir).absolute()
    workspace.mkdir(parents=True, exist_ok=True)

    # æ˜¾ç¤ºå¯åŠ¨ bannerï¼ˆå¸¦åŠ¨ç”»ï¼‰
    print_banner(
        model=config.llm.model,
        provider=config.llm.provider,
        workspace=str(workspace),
        animate=True,
    )

    # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
    print_status(f"æ¨¡å‹: {config.llm.model}", "info")
    print_status(f"Provider: {config.llm.provider}", "info")
    print_status(f"å·¥ä½œç›®å½•: {workspace}", "info")

    # åˆ›å»ºå·¥å…·
    tools = create_tools(config, workspace)
    print_status(f"å·²åŠ è½½ {len(tools)} ä¸ªå†…ç½®å·¥å…·", "ok")

    # åŠ è½½æ’ä»¶
    plugin_mgr = PluginManager()
    plugin_tools = plugin_mgr.load_all_plugins()
    if plugin_tools:
        tools.extend(plugin_tools)
        print_status(f"å·²åŠ è½½ {len(plugin_tools)} ä¸ªæ’ä»¶å·¥å…·", "ok")

    # åŠ è½½ç³»ç»Ÿæç¤ºè¯
    system_prompt = load_system_prompt(config)

    # åˆ›å»º LLM å®¢æˆ·ç«¯
    retry_config = RetryConfig(
        enabled=config.llm.retry.enabled,
        max_retries=config.llm.retry.max_retries,
        initial_delay=config.llm.retry.initial_delay,
        max_delay=config.llm.retry.max_delay,
        exponential_base=config.llm.retry.exponential_base,
    )

    llm_client = LLMClient(
        api_key=config.llm.api_key,
        api_base=config.llm.api_base,
        model=config.llm.model,
        provider=config.llm.provider,
        retry_config=retry_config,
    )

    # åˆ›å»ºä¼šè¯ç®¡ç†å™¨
    session_mgr = SessionManager()

    # åˆ›å»º Agent
    agent = Agent(
        llm_client=llm_client,
        system_prompt=system_prompt,
        tools=tools,
        max_steps=config.agent.max_steps,
        workspace_dir=str(workspace),
        stream=stream,
        enable_thinking=thinking,
    )

    print_ready()

    # è¿›å…¥äº¤äº’å¾ªç¯
    await interactive_loop(agent, session_mgr, plugin_mgr, display)


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="å°é“ - AI ç¼–ç¨‹åŠ©æ‰‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  xiaotie                    # å¯åŠ¨äº¤äº’å¼ CLI
  xiaotie --tui              # å¯åŠ¨ TUI æ¨¡å¼
  xiaotie -p "ä½ å¥½"          # éäº¤äº’æ¨¡å¼
  xiaotie -p "åˆ†æä»£ç " -f json  # JSON è¾“å‡º
        """,
    )

    parser.add_argument(
        "-p", "--prompt",
        type=str,
        help="éäº¤äº’æ¨¡å¼ï¼šç›´æ¥æ‰§è¡Œæç¤ºè¯",
    )
    parser.add_argument(
        "-f", "--format",
        type=str,
        choices=["text", "json"],
        default="text",
        help="è¾“å‡ºæ ¼å¼ (é»˜è®¤: text)",
    )
    parser.add_argument(
        "-q", "--quiet",
        action="store_true",
        help="å®‰é™æ¨¡å¼ï¼šåªè¾“å‡ºç»“æœ",
    )
    parser.add_argument(
        "--tui",
        action="store_true",
        help="å¯åŠ¨ TUI æ¨¡å¼",
    )
    parser.add_argument(
        "--no-stream",
        action="store_true",
        help="ç¦ç”¨æµå¼è¾“å‡º",
    )
    parser.add_argument(
        "--no-thinking",
        action="store_true",
        help="ç¦ç”¨æ·±åº¦æ€è€ƒ",
    )
    parser.add_argument(
        "-v", "--version",
        action="version",
        version=f"å°é“ XiaoTie v{VERSION}",
    )

    args = parser.parse_args()

    # TUI æ¨¡å¼
    if args.tui:
        try:
            from .tui.main import run_tui
            run_tui()
        except ImportError as e:
            print(f"âŒ TUI æ¨¡å¼éœ€è¦å®‰è£… textual: pip install textual")
            print(f"   é”™è¯¯: {e}")
            sys.exit(1)
        return

    # éäº¤äº’æ¨¡å¼
    if args.prompt:
        asyncio.run(run_non_interactive(
            prompt=args.prompt,
            output_format=args.format,
            quiet=args.quiet,
            stream=not args.no_stream,
            thinking=not args.no_thinking,
        ))
        return

    # äº¤äº’æ¨¡å¼
    asyncio.run(main_async(
        stream=not args.no_stream,
        thinking=not args.no_thinking,
    ))


async def run_non_interactive(
    prompt: str,
    output_format: str = "text",
    quiet: bool = False,
    stream: bool = True,
    thinking: bool = True,
):
    """éäº¤äº’æ¨¡å¼"""
    # åŠ è½½é…ç½®
    try:
        config = Config.load()
    except (FileNotFoundError, ValueError) as e:
        if output_format == "json":
            print(json.dumps({"error": str(e)}, ensure_ascii=False))
        else:
            print(f"âŒ é…ç½®é”™è¯¯: {e}")
        sys.exit(1)

    # åˆ›å»ºå·¥ä½œç›®å½•
    workspace = Path(config.agent.workspace_dir).absolute()
    workspace.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºå·¥å…·
    tools = create_tools(config, workspace)

    # åŠ è½½æ’ä»¶
    plugin_mgr = PluginManager()
    plugin_tools = plugin_mgr.load_all_plugins()
    if plugin_tools:
        tools.extend(plugin_tools)

    # åŠ è½½ç³»ç»Ÿæç¤ºè¯
    system_prompt = load_system_prompt(config)

    # åˆ›å»º LLM å®¢æˆ·ç«¯
    retry_config = RetryConfig(
        enabled=config.llm.retry.enabled,
        max_retries=config.llm.retry.max_retries,
        initial_delay=config.llm.retry.initial_delay,
        max_delay=config.llm.retry.max_delay,
        exponential_base=config.llm.retry.exponential_base,
    )

    llm_client = LLMClient(
        api_key=config.llm.api_key,
        api_base=config.llm.api_base,
        model=config.llm.model,
        provider=config.llm.provider,
        retry_config=retry_config,
    )

    # åˆ›å»º Agent
    # JSON è¾“å‡ºæ¨¡å¼ä¸‹ç¦ç”¨æµå¼è¾“å‡ºå’Œå·¥å…·æ‰“å°
    use_stream = stream and not quiet and output_format != "json"
    use_quiet = quiet or output_format == "json"
    agent = Agent(
        llm_client=llm_client,
        system_prompt=system_prompt,
        tools=tools,
        max_steps=config.agent.max_steps,
        workspace_dir=str(workspace),
        stream=use_stream,
        enable_thinking=thinking,
        quiet=use_quiet,
    )

    # è¿è¡Œ
    try:
        result = await agent.run(prompt)

        if output_format == "json":
            output = {
                "success": True,
                "result": result,
                "tokens": agent.api_total_tokens,
                "model": config.llm.model,
            }
            print(json.dumps(output, ensure_ascii=False, indent=2))
        else:
            # æµå¼æ¨¡å¼ä¸‹å†…å®¹å·²ç»é€šè¿‡å›è°ƒæ‰“å°ï¼Œä¸éœ€è¦å†æ‰“å°
            if not use_stream:
                if not quiet:
                    print()
                print(result)

    except Exception as e:
        if output_format == "json":
            print(json.dumps({"error": str(e)}, ensure_ascii=False))
        else:
            print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
