"""ä»£ç åº“æ˜ å°„æ¨¡å—

å­¦ä¹ è‡ª Aider çš„ RepoMap è®¾è®¡ï¼š
- è‡ªåŠ¨åˆ†æé¡¹ç›®ç»“æ„
- æå–ä»£ç å®šä¹‰ï¼ˆç±»ã€å‡½æ•°ï¼‰
- æ™ºèƒ½ä¸Šä¸‹æ–‡é€‰æ‹©
- Token é¢„ç®—ç®¡ç†
"""

from __future__ import annotations

import os
import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Set

# å¸¸è§çš„å¿½ç•¥æ¨¡å¼
DEFAULT_IGNORE_PATTERNS = {
    # ç›®å½•
    ".git", ".svn", ".hg",
    "node_modules", "__pycache__", ".pytest_cache",
    "venv", ".venv", "env", ".env",
    "dist", "build", ".next", ".nuxt",
    "target", "out", "bin", "obj",
    ".idea", ".vscode", ".eclipse",
    "coverage", ".nyc_output",
    # æ–‡ä»¶æ¨¡å¼
    "*.pyc", "*.pyo", "*.so", "*.dll", "*.dylib",
    "*.egg-info", "*.egg",
    "*.min.js", "*.min.css",
    "*.map", "*.lock",
    "package-lock.json", "yarn.lock", "pnpm-lock.yaml",
}

# ä»£ç æ–‡ä»¶æ‰©å±•å
CODE_EXTENSIONS = {
    ".py", ".js", ".ts", ".jsx", ".tsx",
    ".java", ".kt", ".scala",
    ".go", ".rs", ".c", ".cpp", ".h", ".hpp",
    ".rb", ".php", ".swift", ".m",
    ".cs", ".fs", ".vb",
    ".lua", ".pl", ".r",
    ".sh", ".bash", ".zsh",
    ".sql", ".graphql",
    ".vue", ".svelte",
}

# é‡è¦æ–‡ä»¶ï¼ˆä¼˜å…ˆæ˜¾ç¤ºï¼‰
IMPORTANT_FILES = {
    "README.md", "README.rst", "README.txt", "README",
    "setup.py", "pyproject.toml", "setup.cfg",
    "package.json", "tsconfig.json",
    "Cargo.toml", "go.mod", "build.gradle",
    "Makefile", "CMakeLists.txt",
    "Dockerfile", "docker-compose.yml",
    ".env.example", "config.yaml", "config.json",
}


@dataclass
class CodeDefinition:
    """ä»£ç å®šä¹‰"""
    name: str
    kind: str  # class, function, method, variable
    file_path: str
    line_number: int
    signature: str = ""


@dataclass
class FileInfo:
    """æ–‡ä»¶ä¿¡æ¯"""
    path: str
    relative_path: str
    size: int
    lines: int = 0
    definitions: List[CodeDefinition] = field(default_factory=list)
    is_important: bool = False


class RepoMap:
    """ä»£ç åº“æ˜ å°„"""

    def __init__(
        self,
        workspace_dir: str,
        ignore_patterns: Optional[Set[str]] = None,
        max_file_size: int = 100_000,  # 100KB
    ):
        self.workspace = Path(workspace_dir).absolute()
        self.ignore_patterns = ignore_patterns or DEFAULT_IGNORE_PATTERNS
        self.max_file_size = max_file_size
        self._cache: Dict[str, FileInfo] = {}

    def _should_ignore(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥"""
        name = path.name

        # æ£€æŸ¥ç›®å½•/æ–‡ä»¶å
        if name in self.ignore_patterns:
            return True

        # æ£€æŸ¥é€šé…ç¬¦æ¨¡å¼
        for pattern in self.ignore_patterns:
            if pattern.startswith("*") and name.endswith(pattern[1:]):
                return True

        # æ£€æŸ¥éšè—æ–‡ä»¶ï¼ˆé™¤äº†é‡è¦çš„é…ç½®æ–‡ä»¶ï¼‰
        if name.startswith(".") and name not in {".env.example", ".gitignore"}:
            return True

        return False

    def _is_code_file(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç æ–‡ä»¶"""
        return path.suffix.lower() in CODE_EXTENSIONS

    def _extract_python_definitions(self, content: str, file_path: str) -> List[CodeDefinition]:
        """æå– Python ä»£ç å®šä¹‰"""
        definitions = []

        # åŒ¹é…ç±»å®šä¹‰
        class_pattern = r'^class\s+(\w+)(?:\([^)]*\))?:'
        for match in re.finditer(class_pattern, content, re.MULTILINE):
            line_num = content[:match.start()].count('\n') + 1
            definitions.append(CodeDefinition(
                name=match.group(1),
                kind="class",
                file_path=file_path,
                line_number=line_num,
                signature=match.group(0).rstrip(':'),
            ))

        # åŒ¹é…å‡½æ•°å®šä¹‰
        func_pattern = r'^(?:async\s+)?def\s+(\w+)\s*\([^)]*\)(?:\s*->\s*[^:]+)?:'
        for match in re.finditer(func_pattern, content, re.MULTILINE):
            line_num = content[:match.start()].count('\n') + 1
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–¹æ³•ï¼ˆç¼©è¿›ï¼‰
            line_start = content.rfind('\n', 0, match.start()) + 1
            indent = match.start() - line_start
            kind = "method" if indent > 0 else "function"

            definitions.append(CodeDefinition(
                name=match.group(1),
                kind=kind,
                file_path=file_path,
                line_number=line_num,
                signature=match.group(0).rstrip(':'),
            ))

        return definitions

    def _extract_js_definitions(self, content: str, file_path: str) -> List[CodeDefinition]:
        """æå– JavaScript/TypeScript ä»£ç å®šä¹‰"""
        definitions = []

        # åŒ¹é…ç±»å®šä¹‰
        class_pattern = r'(?:export\s+)?class\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*\{'
        for match in re.finditer(class_pattern, content):
            line_num = content[:match.start()].count('\n') + 1
            definitions.append(CodeDefinition(
                name=match.group(1),
                kind="class",
                file_path=file_path,
                line_number=line_num,
            ))

        # åŒ¹é…å‡½æ•°å®šä¹‰
        func_patterns = [
            r'(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\(',
            r'(?:export\s+)?const\s+(\w+)\s*=\s*(?:async\s+)?\([^)]*\)\s*=>',
            r'(?:export\s+)?const\s+(\w+)\s*=\s*(?:async\s+)?function',
        ]
        for pattern in func_patterns:
            for match in re.finditer(pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                definitions.append(CodeDefinition(
                    name=match.group(1),
                    kind="function",
                    file_path=file_path,
                    line_number=line_num,
                ))

        return definitions

    def _extract_definitions(self, content: str, file_path: str) -> List[CodeDefinition]:
        """æå–ä»£ç å®šä¹‰"""
        suffix = Path(file_path).suffix.lower()

        if suffix == ".py":
            return self._extract_python_definitions(content, file_path)
        elif suffix in {".js", ".ts", ".jsx", ".tsx"}:
            return self._extract_js_definitions(content, file_path)

        return []

    def scan_files(self) -> List[FileInfo]:
        """æ‰«æå·¥ä½œç›®å½•ä¸­çš„æ–‡ä»¶"""
        files = []

        for root, dirs, filenames in os.walk(self.workspace):
            # è¿‡æ»¤ç›®å½•
            dirs[:] = [d for d in dirs if not self._should_ignore(Path(root) / d)]

            for filename in filenames:
                file_path = Path(root) / filename

                if self._should_ignore(file_path):
                    continue

                try:
                    stat = file_path.stat()
                    if stat.st_size > self.max_file_size:
                        continue

                    relative_path = str(file_path.relative_to(self.workspace))
                    is_important = filename in IMPORTANT_FILES

                    file_info = FileInfo(
                        path=str(file_path),
                        relative_path=relative_path,
                        size=stat.st_size,
                        is_important=is_important,
                    )

                    # å¯¹ä»£ç æ–‡ä»¶æå–å®šä¹‰
                    if self._is_code_file(file_path):
                        try:
                            content = file_path.read_text(encoding="utf-8", errors="ignore")
                            file_info.lines = content.count('\n') + 1
                            file_info.definitions = self._extract_definitions(content, relative_path)
                        except Exception:
                            pass

                    files.append(file_info)
                    self._cache[relative_path] = file_info

                except (OSError, PermissionError):
                    continue

        return files

    def get_tree(self, max_depth: int = 3) -> str:
        """ç”Ÿæˆç›®å½•æ ‘"""
        lines = [f"ğŸ“ {self.workspace.name}/"]

        def add_tree(path: Path, prefix: str, depth: int):
            if depth > max_depth:
                return

            try:
                items = sorted(path.iterdir(), key=lambda x: (not x.is_dir(), x.name.lower()))
            except PermissionError:
                return

            # è¿‡æ»¤
            items = [i for i in items if not self._should_ignore(i)]

            for i, item in enumerate(items):
                is_last = i == len(items) - 1
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                new_prefix = prefix + ("    " if is_last else "â”‚   ")

                if item.is_dir():
                    lines.append(f"{prefix}{connector}ğŸ“ {item.name}/")
                    add_tree(item, new_prefix, depth + 1)
                else:
                    icon = "ğŸ“„"
                    if item.name in IMPORTANT_FILES:
                        icon = "â­"
                    elif self._is_code_file(item):
                        icon = "ğŸ“"
                    lines.append(f"{prefix}{connector}{icon} {item.name}")

        add_tree(self.workspace, "", 1)
        return "\n".join(lines)

    def get_repo_map(self, max_tokens: int = 2000) -> str:
        """ç”Ÿæˆä»£ç åº“æ¦‚è§ˆ

        Args:
            max_tokens: æœ€å¤§ token æ•°ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰

        Returns:
            ä»£ç åº“æ¦‚è§ˆæ–‡æœ¬
        """
        files = self.scan_files()

        # æŒ‰é‡è¦æ€§å’Œå®šä¹‰æ•°é‡æ’åº
        files.sort(key=lambda f: (
            -int(f.is_important),
            -len(f.definitions),
            f.relative_path,
        ))

        lines = ["# ä»£ç åº“æ¦‚è§ˆ\n"]

        # æ·»åŠ ç›®å½•æ ‘
        tree = self.get_tree(max_depth=2)
        lines.append("## ç›®å½•ç»“æ„\n```")
        lines.append(tree)
        lines.append("```\n")

        # æ·»åŠ ä»£ç å®šä¹‰
        lines.append("## ä»£ç å®šä¹‰\n")

        current_tokens = sum(len(line) // 4 for line in lines)

        for file_info in files:
            if not file_info.definitions:
                continue

            file_section = [f"### {file_info.relative_path}"]
            for defn in file_info.definitions:
                if defn.kind == "class":
                    file_section.append(f"  - ğŸ“¦ `{defn.name}` (class, L{defn.line_number})")
                elif defn.kind == "function":
                    file_section.append(f"  - ğŸ”§ `{defn.name}` (function, L{defn.line_number})")
                elif defn.kind == "method":
                    file_section.append(f"  - ğŸ”¹ `{defn.name}` (method, L{defn.line_number})")

            section_tokens = sum(len(line) // 4 for line in file_section)

            if current_tokens + section_tokens > max_tokens:
                lines.append("\n... (æ›´å¤šæ–‡ä»¶çœç•¥)")
                break

            lines.extend(file_section)
            current_tokens += section_tokens

        return "\n".join(lines)

    def find_relevant_files(self, query: str, limit: int = 10) -> List[FileInfo]:
        """æ ¹æ®æŸ¥è¯¢æ‰¾ç›¸å…³æ–‡ä»¶

        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ç›¸å…³æ–‡ä»¶åˆ—è¡¨
        """
        if not self._cache:
            self.scan_files()

        query_lower = query.lower()
        query_words = set(query_lower.split())

        scored_files = []

        for file_info in self._cache.values():
            score = 0

            # æ–‡ä»¶ååŒ¹é…
            filename = Path(file_info.relative_path).name.lower()
            if query_lower in filename:
                score += 10
            for word in query_words:
                if word in filename:
                    score += 5

            # è·¯å¾„åŒ¹é…
            path_lower = file_info.relative_path.lower()
            for word in query_words:
                if word in path_lower:
                    score += 2

            # å®šä¹‰åç§°åŒ¹é…
            for defn in file_info.definitions:
                defn_name_lower = defn.name.lower()
                if query_lower in defn_name_lower:
                    score += 8
                for word in query_words:
                    if word in defn_name_lower:
                        score += 3

            # é‡è¦æ–‡ä»¶åŠ åˆ†
            if file_info.is_important:
                score += 3

            if score > 0:
                scored_files.append((score, file_info))

        # æŒ‰åˆ†æ•°æ’åº
        scored_files.sort(key=lambda x: -x[0])

        return [f for _, f in scored_files[:limit]]
